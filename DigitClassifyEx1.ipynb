{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handson0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5xPxmz-jCVCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1407
        },
        "outputId": "ba37641a-0cb4-47df-bd82-73f8b6416a46"
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(x_train.shape)\n",
        "print(x_train.dtype)\n",
        "%matplotlib inline\n",
        "plt.imshow(x_train[2])\n",
        "plt.show()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(x_train.shape[1], 'training sample')\n",
        "print(y_test[1], 'test labels')\n",
        "\n",
        "Input = Input(shape=(x_train.shape[1],))\n",
        "layer = Dense(64, activation='relu')(Input)\n",
        "layer = Dense(64, activation='relu')(layer)\n",
        "predictions = Dense(10, activation='softmax')(layer)\n",
        "\n",
        "# This creates a model that includes\n",
        "# the Input layer and three Dense layers\n",
        "model = Model(inputs=Input, outputs=predictions)\n",
        "print(model.summary())\n",
        "import pdb; pdb.set_trace()\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                    epochs=epochs)  # starts training\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "uint8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0e34a1a6d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(784, 'training sample')\n",
            "(array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'test labels')\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--Return--\n",
            "> <ipython-input-9-62bc28f480ed>(50)<module>()->None\n",
            "-> import pdb; pdb.set_trace()\n",
            "(Pdb) c\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.3819 - acc: 0.8953\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.1835 - acc: 0.9465\n",
            "Epoch 3/20\n",
            "40832/60000 [===================>..........] - ETA: 0s - loss: 0.1351 - acc: 0.9606"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.1330 - acc: 0.9610\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.1036 - acc: 0.9693\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0864 - acc: 0.9743\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0736 - acc: 0.9782\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0630 - acc: 0.9811\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0561 - acc: 0.9831\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0496 - acc: 0.9847\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0440 - acc: 0.9869\n",
            "Epoch 11/20\n",
            " 9344/60000 [===>..........................] - ETA: 1s - loss: 0.0335 - acc: 0.9895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0393 - acc: 0.9880\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0342 - acc: 0.9899\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0315 - acc: 0.9906\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0283 - acc: 0.9910\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 1s 22us/step - loss: 0.0252 - acc: 0.9926\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0225 - acc: 0.9931\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0208 - acc: 0.9938\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0185 - acc: 0.9945\n",
            "Epoch 19/20\n",
            " 4608/60000 [=>............................] - ETA: 1s - loss: 0.0173 - acc: 0.9952"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0171 - acc: 0.9947\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 1s 23us/step - loss: 0.0152 - acc: 0.9956\n",
            "('Test loss:', 0.10042614299047163)\n",
            "('Test accuracy:', 0.9769)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "duZ-ucnNVWZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras as kr\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "\n",
        "\n",
        "A = np.array([[1,2,3,4],\n",
        "            [3,4,5,6],\n",
        "            [5,6,7,8]])\n",
        "\n",
        "#(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "#print(A)\n",
        "#import pdb; pdb.set_trace()\n",
        "cal = A.sum(axis=0)\n",
        "#print(type(cal))\n",
        "#print(cal)\n",
        "prc = 100*A/cal.reshape(1,4)\n",
        "#print(prc)\n",
        "b = np.array([[1,2,3,4]])\n",
        "#print(b.shape)\n",
        "\n",
        "gv = np.random.randn(5)\n",
        "#print(type(gv))\n",
        "\n",
        "#print(gv.T)\n",
        "#(gv.shape)\n",
        "\n",
        "xy = np.random.rand(1,10)\n",
        "print(xy)\n",
        "\n",
        "\n",
        "\n",
        "x = np.array([[1,2],[3,4]])\n",
        "y = np.array([[5,6],[7,8]])\n",
        "\n",
        "v = np.array([9,10])\n",
        "w = np.array([11, 12])\n",
        "\n",
        "# Inner product of vectors; both produce 219\n",
        "print(v.dot(w))\n",
        "print(np.dot(v, w))\n",
        "\n",
        "# Matrix / vector product; both produce the rank 1 array [29 67]\n",
        "#print(x.dot(v))\n",
        "#print(np.dot(x, v)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pur20asfRhi4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d_SkFYiFVB58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}
